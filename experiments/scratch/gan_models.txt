# def step(self,
    #          x: Tensor,
    #          edge_index: Tensor,
    #          edge_attr: Tensor,
    #          batch_mask: Tensor,
    #          optimizer_idx: int) -> Dict:
    #
    #
    #
    #     # train generator
    #
    #     if optimizer_idx == 0:
    #         # generate images
    #         # ground truth result (ie: all fake)
    #         # put on GPU because we created this tensor inside training_loop
    #         valid = torch.ones(self.batch_size, 1)
    #         valid = valid.type_as(x)
    #
    #         # adversarial loss is binary cross-entropy
    #         g_loss = self.adversarial_loss(self.discriminator(torch.cat(self(z), dim=1)), valid)
    #         tqdm_dict = {'g_loss': g_loss}
    #         output = OrderedDict({
    #             'loss': g_loss,
    #             'progress_bar': tqdm_dict,
    #             'log': tqdm_dict
    #         })
    #         return output
    #
    #     # train discriminator
    #     if optimizer_idx == 1:
    #         # Measure discriminator's ability to classify real from generated samples
    #
    #         # how well can it label as real?
    #         valid = torch.ones(self.batch_size, 1)
    #         valid = valid.type_as(x)
    #
    #         x, real_data_indices = to_dense_batch(x, batch_mask,
    #                                               max_num_nodes=self.max_nodes_in_graph)
    #         padding_indicators = torch.zeros(self.batch_size, self.max_nodes_in_graph, 1)
    #         x = torch.cat([padding_indicators, x], 2)
    #         adj = to_dense_adj(edge_index, batch_mask, edge_attr,
    #                            max_num_nodes=self.max_nodes_in_graph)
    #         padding_indicators = padding_indicators.unsqueeze(2).expand(-1, -1,
    #                                                                     self.max_nodes_in_graph, -1)
    #         adj = torch.cat([padding_indicators, adj], 3)
    #         indices = torch.tril_indices(self.max_nodes_in_graph, self.max_nodes_in_graph, -1)
    #         adj = adj[:, indices[0], indices[1]]
    #
    #         adj = adj.view(self.batch_size, -1)
    #         x = x.view(self.batch_size, -1)
    #
    #         real_loss = self.adversarial_loss(
    #             self.discriminator(torch.cat((x, adj), dim=1)), valid)
    #
    #         # how well can it label as fake?
    #         fake = torch.zeros(self.batch_size, 1)
    #         fake = fake.type_as(x)
    #
    #         fake_loss = self.adversarial_loss(
    #             self.discriminator(torch.cat(self(z), dim=1).detach()), fake)
    #
    #         # discriminator loss is the average of these
    #         d_loss = (real_loss + fake_loss) / 2
    #         tqdm_dict = {'d_loss': d_loss}
    #         output = OrderedDict({
    #             'loss': d_loss,
    #             'progress_bar': tqdm_dict,
    #             'log': tqdm_dict
    #         })
    #         return output

# def on_epoch_end(self):
    #     z = self.validation_z.type_as(self.generator.model[0].weight)
    #
    #     # log sampled images
    #     nodes, edges = self(z)
    #     nodes = nodes.reshape(8, self.max_nodes_in_graph, self.node_dim)
    #     edges = edges.reshape(8,
    #                           (comb(self.max_nodes_in_graph + 1, 2, exact=True) - self.max_nodes_in_graph),
    #                           self.edge_dim)
    #     edges = torch.argmax(edges, dim=-1).detach().numpy()
    #     nodes = torch.argmax(nodes, dim=-1).detach().numpy()
    #     for i in range(nodes.shape[0]):
    #         mol = matrices2mol(nodes[i], edges[i])
    #         if mol != None:
    #             Draw.MolToFile(mol, "{}.svg".format(i))

        # grid = torchvision.utils.make_grid(sample_imgs)
        # self.logger.experiment.add_image('generated_images', grid, self.current_epoch)